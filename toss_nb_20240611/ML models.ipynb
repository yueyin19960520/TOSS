{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c6e634d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\GFOS\\lib\\site-packages\\pkg_resources\\__init__.py:119: PkgResourcesDeprecationWarning: -PKG-VERSION is an invalid version and will not be supported in a future release\n",
      "  PkgResourcesDeprecationWarning,\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn import metrics\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, precision_recall_curve\n",
    "\n",
    "#################################################################################################################\n",
    "################################################PRESET PARAMETERS################################################\n",
    "#################################################################################################################\n",
    "\n",
    "def standardize(col):\n",
    "    return (col - np.mean(col)) / np.std(col)\n",
    "\n",
    "def absolute_correct_rate(y_pred, y_true):\n",
    "        score = 0\n",
    "        y_pred = np.array(y_pred)\n",
    "        y_true = np.array(y_true)\n",
    "        for i in range(y_pred.shape[0]):\n",
    "            t = np.where(max(y_true[i]) == y_true[i], 1, 0)\n",
    "            p = np.where(max(y_pred[i]) == y_pred[i], 1, 0)\n",
    "            if (t==p).all():\n",
    "                score += 1\n",
    "        return score/y_pred.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "664547e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting pre_load graph dicts...\n",
      "Failed of getting pre_load graph dicts...\n",
      "Getting the all datapoint from the TOSS result dictonary...\n",
      "Done!\n",
      "259775\n",
      "Preparing the datasets...\n",
      "Done!\n",
      "Saving the prepared datasets...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "seed = 42\n",
    "path = \"D:/share/TOSS\"#os.path.split(os.path.abspath(os.path.dirname(__file__)))[0]\n",
    "model_path = path + \"/models\"\n",
    "\n",
    "try:\n",
    "    print(\"Getting pre_load graph dicts...\")\n",
    "    file_get = open(path + \"/ML_NC_split_dataset.pkl\",\"rb\")\n",
    "    (data_tr_y, data_tr_x, data_vl_y, data_vl_x, data_te_y, data_te_x) = pickle.load(file_get)\n",
    "    file_get.close()\n",
    "    print(\"Done!\")\n",
    "except:\n",
    "    print(\"Failed of getting pre_load graph dicts...\")\n",
    "    print(\"Getting the all datapoint from the TOSS result dictonary...\")\n",
    "    file_get= open(path + \"/graphs_dict.pkl\",\"rb\")\n",
    "    graphs_dict = pickle.load(file_get)\n",
    "    file_get.close()\n",
    "    print(\"Done!\")\n",
    "    print(len(graphs_dict))\n",
    "    \n",
    "    print(\"Preparing the datasets...\")\n",
    "    columns = graphs_dict[\"mp-31770.cif\"][\"n\"].columns.to_list()\n",
    "    all_data = np.vstack(list(map(lambda x:x[\"n\"], list(graphs_dict.values()))))\n",
    "    ML_data = pd.DataFrame(all_data, columns=columns)\n",
    "    #ML_data.to_csv(path + \"/ML_data.csv\")\n",
    "\n",
    "    ML_data[columns[0:-1]] = ML_data[columns[0:-1]].apply(standardize, axis=0)\n",
    "\n",
    "    all_idx = np.arange(ML_data.shape[0])\n",
    "    random.shuffle(all_idx)\n",
    "    N = len(all_idx)\n",
    "    tr_idx = all_idx[0:8*N//10]\n",
    "    vl_idx = all_idx[8*N//10:9*N//10]\n",
    "    te_idx = all_idx[9*N//10:]\n",
    "\n",
    "    data_tr = ML_data.iloc[tr_idx,:].reset_index(drop=True)\n",
    "    data_vl = ML_data.iloc[vl_idx,:].reset_index(drop=True)\n",
    "    data_te = ML_data.iloc[te_idx,:].reset_index(drop=True)\n",
    "\n",
    "    data_tr_y = data_tr[\"OS\"].values.reshape(-1, 1).ravel()\n",
    "    data_tr_x = np.array(data_tr.iloc[:,:-1].values)\n",
    "    \n",
    "    data_vl_y = data_vl[\"OS\"].values.reshape(-1, 1).ravel()\n",
    "    data_vl_x = np.array(data_vl.iloc[:,:-1].values)\n",
    "    \n",
    "    data_te_y = data_te[\"OS\"].values.reshape(-1, 1).ravel()\n",
    "    data_te_x = np.array(data_te.iloc[:,:-1].values)\n",
    "    print(\"Done!\")\n",
    "\n",
    "\n",
    "    print(\"Saving the prepared datasets...\")\n",
    "    file_save= open(path + \"/ML_NC_split_dataset.pkl\",\"wb\")\n",
    "    pickle.dump((data_tr_y, data_tr_x, data_vl_y, data_vl_x, data_te_y, data_te_x), file_save)\n",
    "    file_save.close()\n",
    "    print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2dfbf4ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Give the name of the model from 'RF_200, RF_2000, XGB_200, XGB_2000':XGB_200\n",
      "Model training...\n",
      "Validate ROC:0.9971219527063613, Validate Rate:0.9411011933326935, Test ROC:0.9972329156027887, Test Rate:0.9415378005891238.\n",
      "ALL data: ROC:0.9974663020676676, Correct Rate:0.9430699472392952.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'END HERE'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "\n",
    "    RF_2000 = RandomForestClassifier(n_estimators=2000, max_depth=25, min_impurity_decrease=0, criterion='entropy',\n",
    "                                     min_samples_leaf=50,min_samples_split=50, max_leaf_nodes=None,\n",
    "                                     n_jobs=48, random_state=1, verbose=0, class_weight='balanced')\n",
    "\n",
    "    RF_200 = RandomForestClassifier(n_estimators=200, max_depth=25, min_impurity_decrease=0, criterion='entropy',\n",
    "                                    min_samples_leaf=50,min_samples_split=50, max_leaf_nodes=None,\n",
    "                                    n_jobs=48, random_state=1, verbose=0, class_weight='balanced')\n",
    "\n",
    "    XGB_2000 = XGBClassifier(booster=\"gbtree\", verbosity=0, n_jobs=48,\n",
    "                             n_estimators=2000, max_depth=20, min_child_weight=1, subsample=1, colsample_bytree=1, \n",
    "                             learning_rate=0.01, gamma=0, random_state=1)\n",
    "\n",
    "    XGB_200 = XGBClassifier(booster=\"gbtree\", verbosity=0, n_jobs=48,\n",
    "                            n_estimators=200, max_depth=20, min_child_weight=1, subsample=1, colsample_bytree=1, \n",
    "                            learning_rate=0.01, gamma=0, random_state=1)\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    oe = OneHotEncoder()\n",
    "\n",
    "    model_name = str(input(\"Give the name of the model from 'RF_200, RF_2000, XGB_200, XGB_2000':\"))\n",
    "\n",
    "    exec(\"model = %s\"%model_name)\n",
    "\n",
    "    print(\"Model training...\")\n",
    "    model.fit(data_tr_x, le.fit_transform(data_tr_y))\n",
    "\n",
    "    try:\n",
    "        model.save_model(model_path + \"/%s.json\"%model_name)\n",
    "    except:\n",
    "        joblib.dump(model, model_path+\"/%s.json\"%model_name)\n",
    "\n",
    "    vl_preds = model.predict_proba(data_vl_x)\n",
    "    vl_labels = oe.fit_transform(data_vl_y.reshape(-1,1)).toarray() #one_hot encode!!\n",
    "    vl_roc = roc_auc_score(vl_labels, vl_preds, multi_class=\"ovo\")\n",
    "    vl_score = absolute_correct_rate(vl_preds, vl_labels)\n",
    "\n",
    "    te_preds = model.predict_proba(data_te_x)\n",
    "    te_labels = oe.fit_transform(data_te_y.reshape(-1,1)).toarray() #one_hot encode!!\n",
    "    te_roc = roc_auc_score(te_labels, te_preds, multi_class=\"ovo\")\n",
    "    te_score = absolute_correct_rate(te_preds, te_labels)\n",
    "\n",
    "    print(\"Validate ROC:%s, Validate Rate:%s, Test ROC:%s, Test Rate:%s.\"%(vl_roc, vl_score, te_roc, te_score))\n",
    "\n",
    "    data_all_x = np.vstack((data_te_x, data_vl_x, data_tr_x))\n",
    "    data_all_y = np.hstack((data_te_y, data_vl_y, data_tr_y))\n",
    "\n",
    "    all_preds = model.predict_proba(data_all_x)\n",
    "    all_labels = oe.fit_transform(data_all_y.reshape(-1,1)).toarray()\n",
    "    all_roc = roc_auc_score(all_labels, all_preds, multi_class=\"ovo\")\n",
    "    all_score = absolute_correct_rate(all_preds, all_labels)\n",
    "\n",
    "    print(\"ALL data: ROC:%s, Correct Rate:%s.\"%(all_roc, all_score))\n",
    "    \n",
    "    with open(file=\"../models/%s.txt\"%model_name, mode=\"a\",encoding=\"utf-8\") as f:\n",
    "        f.write(\"Validate ROC,%s,Validate Rate,%s\\n\"%(vl_roc, vl_score))\n",
    "        f.write(\"Test ROC,%s,Test Rate,%s\\n\"%(te_roc, te_score))\n",
    "\"\"\"END HERE\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af7eb82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "temp_model = XGBClassifier(booster=\"gbtree\", verbosity=0, n_jobs=48,\n",
    "                             n_estimators=2000, max_depth=20, min_child_weight=1, subsample=1, colsample_bytree=1, \n",
    "                             learning_rate=0.01, gamma=0, random_state=1)\n",
    "\n",
    "temp_model.load_model(\"../models/XGB_2000.json\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "170477dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1\n"
     ]
    }
   ],
   "source": [
    "os_list = [-5, -3, -1, 0, 1, 2, 3]\n",
    "\n",
    "v = -2\n",
    "\n",
    "n = os_list[os_list.index(min([os for os in os_list if os > v]))]\n",
    "\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e086abe3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GFOS",
   "language": "python",
   "name": "gfos"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
