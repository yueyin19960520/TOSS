{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "818e0f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"./\")\n",
    "import time\n",
    "import pickle\n",
    "import os\n",
    "import random\n",
    "import openpyxl\n",
    "import argparse\n",
    "import copy\n",
    "import pandas as pd\n",
    "\n",
    "from get_fos import GET_FOS\n",
    "from result import RESULT\n",
    "from pre_set import PRE_SET\n",
    "from digest import DIGEST\n",
    "from get_structure import GET_STRUCTURE\n",
    "from initialization import INITIAL\n",
    "from first_algo import FIRST_ALGO\n",
    "from second_algo import SECOND_ALGO\n",
    "from resonance import RESONANCE\n",
    "from tune import TUNE\n",
    "from post_process import *\n",
    "from auxilary import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3698a0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.dirname(os.getcwd())\n",
    "\n",
    "file_get = open(os.path.join(path,\"valid_t_dict.pkl\"),'rb') \n",
    "valid_t_dict = pickle.load(file_get) \n",
    "file_get.close()\n",
    "\n",
    "\n",
    "file_get= open(os.path.join(path,\"global_normalized_normed_dict.pkl\"),\"rb\")\n",
    "global_normalized_normed_dict = pickle.load(file_get)\n",
    "file_get.close()\n",
    "\n",
    "file_get= open(os.path.join(path,\"global_mean_dict.pkl\"),\"rb\")\n",
    "global_mean_dict = pickle.load(file_get)\n",
    "file_get.close()\n",
    "\n",
    "file_get= open(os.path.join(path,\"global_sigma_dict.pkl\"),\"rb\")\n",
    "global_sigma_dict = pickle.load(file_get)\n",
    "file_get.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "60aee483",
   "metadata": {},
   "outputs": [],
   "source": [
    "from post_process import *\n",
    "import copy\n",
    "import itertools\n",
    "import math\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "class TUNE():\n",
    "\tdef __init__(self):\n",
    "\t\tNone\n",
    "\n",
    "\tdef apply_resonance(self, atom_idx_list, valence_list, LOSS, res, global_nomalized_dict, \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t  global_sigma_dict, \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t  global_mean_dict):\n",
    "\t\tori_LOSS = copy.deepcopy(LOSS)\n",
    "\t\tclasses_dict = classify(atom_idx_list,res)\n",
    "\t\tvalence_with_loss = []\n",
    "\t\tNC = len((classes_dict))\n",
    "\t\tprint(NC)\n",
    "\t\tprint(\"resonance_order:\", res.resonance_order)\n",
    "\t\ttimestamp = time.time()\n",
    "\t\tfor c in classes_dict:\n",
    "\t\t\tfor d in classes_dict:\n",
    "\t\t\t\tif c[0] != d[0]:\n",
    "\t\t\t\t\top_c = classes_dict[c]\n",
    "\t\t\t\t\top_d = classes_dict[d]\n",
    "\n",
    "\t\t\t\t\tnow_valence_list_c = [valence_list[i] for i in op_c]\n",
    "\t\t\t\t\tnow_max_oxi_list_c = [res.max_oxi_list[i] for i in op_c]\n",
    "\t\t\t\t\tnow_min_oxi_list_c = [max(0,res.min_oxi_list[i]) for i in op_c]   #because they are the super atom!\n",
    "\t\t\t\t\tnow_valence_list_d = [valence_list[i] for i in op_d]\n",
    "\t\t\t\t\tnow_max_oxi_list_d = [res.max_oxi_list[i] for i in op_d]\n",
    "\t\t\t\t\tnow_min_oxi_list_d = [max(0,res.min_oxi_list[i]) for i in op_d]   #same reason.\n",
    "\n",
    "\t\t\t\t\tif len(op_c) < len(op_d):\n",
    "\t\t\t\t\t\tnow_valence_list_c = [i + 1 for i in now_valence_list_c]\n",
    "\t\t\t\t\t\tN = len(op_c)\n",
    "\t\t\t\t\t\twhile N != 0:\n",
    "\t\t\t\t\t\t\ttemp_list = sorted([(j, v) for j,v in enumerate(now_valence_list_d)], reverse = True, key = lambda x:x[1])\n",
    "\t\t\t\t\t\t\tnow_valence_list_d[temp_list[0][0]] -= 1\n",
    "\t\t\t\t\t\t\tN -= 1\n",
    "\n",
    "\t\t\t\t\t\ttarget_valence = set(now_valence_list_d)\n",
    "\n",
    "\t\t\t\t\t\t#make sure the volume of the memory!\n",
    "\t\t\t\t\t\ttotal_combi = math.factorial(len(op_d))/math.factorial(len(op_d)-len(op_c))/math.factorial(len(op_c))\n",
    "\t\t\t\t\t\twhile total_combi >= 10000000:\n",
    "\t\t\t\t\t\t\top_d = random.sample(op_d, round(len(op_d)*(4/5)))\n",
    "\t\t\t\t\t\t\ttotal_combi = math.factorial(len(op_d))/math.factorial(len(op_d)-len(op_c))/math.factorial(len(op_c))\n",
    "\t\t\t\t\t\t\tprint(\"47\", total_combi, res.mid)\n",
    "\n",
    "\t\t\t\t\t\tpossible_combi = []\n",
    "\t\t\t\t\t\tfor p in itertools.combinations(op_d, len(op_c)):\n",
    "\t\t\t\t\t\t\tpossible_combi.append(p)\n",
    "\t\t\t\t\t\tnum_sample = round(5000/(NC**2)) if int(res.resonance_order) < 2 else round((5000)**(1/2)/(NC**2))\n",
    "\t\t\t\t\t\tif len(possible_combi) >= num_sample:\n",
    "\t\t\t\t\t\t\tpossible_combi = random.sample(possible_combi, num_sample)\n",
    "\n",
    "\t\t\t\t\t\tresonance = {\"op_d\": possible_combi, \"target_valence\":target_valence}\n",
    "\t\t\t\t\t\t\n",
    "\n",
    "\t\t\t\t\tif len(op_c) > len(op_d):\n",
    "\t\t\t\t\t\tnow_valence_list_d = [j - 1 for j in now_valence_list_d]\n",
    "\t\t\t\t\t\tN = len(op_d)\n",
    "\t\t\t\t\t\twhile N != 0:\n",
    "\t\t\t\t\t\t\ttemp_list = sorted([(i, v) for i,v in enumerate(now_valence_list_c)], reverse = False, key = lambda x:x[1])\n",
    "\t\t\t\t\t\t\tnow_valence_list_c[temp_list[0][0]] += 1\n",
    "\t\t\t\t\t\t\tN -= 1\n",
    "                        \n",
    "\t\t\t\t\t\ttarget_valence = set(now_valence_list_c)\n",
    "\n",
    "\t\t\t\t\t\t#make sure the volume of the memory!\n",
    "\t\t\t\t\t\ttotal_combi = math.factorial(len(op_c))/math.factorial(len(op_c)-len(op_d))/math.factorial(len(op_d))\n",
    "\t\t\t\t\t\twhile total_combi >= 10000000:\n",
    "\t\t\t\t\t\t\top_c = random.sample(op_c, round(len(op_c)*(4/5)))\n",
    "\t\t\t\t\t\t\ttotal_combi = math.factorial(len(op_c))/math.factorial(len(op_c)-len(op_d))/math.factorial(len(op_d))\n",
    "\t\t\t\t\t\t\tprint(\"74\", total_combi, res.mid)\n",
    "\t\t\t\t\t\tpossible_combi = []\n",
    "\n",
    "\t\t\t\t\t\tfor p in itertools.combinations(op_c, len(op_d)):\n",
    "\t\t\t\t\t\t\tpossible_combi.append(p)\n",
    "\t\t\t\t\t\tnum_sample = round(5000/(NC**2)) if int(res.resonance_order) < 2 else round((5000)**(1/2)/(NC**2))\n",
    "\t\t\t\t\t\tif len(possible_combi) >= num_sample:\n",
    "\t\t\t\t\t\t\tpossible_combi = random.sample(possible_combi, num_sample)\n",
    "\n",
    "\t\t\t\t\t\tresonance = {\"op_c\": possible_combi,\"target_valence\":target_valence}\n",
    "\t\t\t\t\t\t\n",
    "\t\t\t\t\t\tprint(num_sample)\n",
    "\t\t\t\t\tif len(op_c) == len(op_d):\n",
    "\t\t\t\t\t\tnow_valence_list_c = [i + 1 for i in now_valence_list_c]\n",
    "\t\t\t\t\t\tnow_valence_list_d = [j - 1 for j in now_valence_list_d]\n",
    "\t\t\t\t\t\tresonance = {\"equal\": [tuple(op_c)]}\n",
    "\n",
    "\t\t\t\t\tif all([now_max_oxi_list_c[i] >= now_valence_list_c[i] for i in range(len(op_c))]) and all(\n",
    "\t\t\t\t\t\t\t[now_min_oxi_list_d[i] <= now_valence_list_d[i] for i in range(len(op_d))]):\n",
    "\n",
    "\t\t\t\t\t\tresonance_result = []\n",
    "\t\t\t\t\t\tif list(resonance.keys())[0] == \"op_d\":\n",
    "\t\t\t\t\t\t\tpossible_valence_list = []\n",
    "\t\t\t\t\t\t\tfor p in resonance[\"op_d\"]:\n",
    "\t\t\t\t\t\t\t\ttemp_sum_of_valence = copy.deepcopy(valence_list)\n",
    "\t\t\t\t\t\t\t\tfor i in op_c:\n",
    "\t\t\t\t\t\t\t\t\ttemp_sum_of_valence[i] += 1\n",
    "\t\t\t\t\t\t\t\tfor j in p:\n",
    "\t\t\t\t\t\t\t\t\ttemp_sum_of_valence[j] -= 1\n",
    "\t\t\t\t\t\t\t\tif set([temp_sum_of_valence[i] for i in op_d]) == resonance[\"target_valence\"]:\n",
    "\t\t\t\t\t\t\t\t\tpossible_valence_list.append(temp_sum_of_valence)                                         \n",
    "\n",
    "\t\t\t\t\t\tif list(resonance.keys())[0] == \"op_c\":\n",
    "\t\t\t\t\t\t\tpossible_valence_list = []\n",
    "\t\t\t\t\t\t\tfor p in resonance[\"op_c\"]:\n",
    "\t\t\t\t\t\t\t\ttemp_sum_of_valence = copy.deepcopy(valence_list)\n",
    "\t\t\t\t\t\t\t\tfor i in p:\n",
    "\t\t\t\t\t\t\t\t\ttemp_sum_of_valence[i] += 1\n",
    "\t\t\t\t\t\t\t\tfor j in op_d:\n",
    "\t\t\t\t\t\t\t\t\ttemp_sum_of_valence[j] -= 1\n",
    "\t\t\t\t\t\t\t\tif set([temp_sum_of_valence[i] for i in op_c]) == resonance[\"target_valence\"]:\n",
    "\t\t\t\t\t\t\t\t\tpossible_valence_list.append(temp_sum_of_valence)\n",
    "\n",
    "\t\t\t\t\t\tif list(resonance.keys())[0] == \"equal\":\n",
    "\t\t\t\t\t\t\ttemp_sum_of_valence = copy.deepcopy(valence_list)\n",
    "\t\t\t\t\t\t\tfor i in op_c:\n",
    "\t\t\t\t\t\t\t\ttemp_sum_of_valence[i] += 1\n",
    "\t\t\t\t\t\t\tfor j in op_d:\n",
    "\t\t\t\t\t\t\t\ttemp_sum_of_valence[j] -= 1\n",
    "\t\t\t\t\t\t\tpossible_valence_list = [temp_sum_of_valence] \n",
    "\n",
    "\t\t\t\t\t\tfor vl in possible_valence_list:\n",
    "\t\t\t\t\t\t\t#print(len(possible_valence_list))\n",
    "\t\t\t\t\t\t\ttemp_pair_info = spider_pair_length_with_CN_unnorm(vl, res)\n",
    "\t\t\t\t\t\t\ttemp_LOSS = cal_loss_func_by_MAP(temp_pair_info,global_nomalized_dict, global_sigma_dict, global_mean_dict)\n",
    "\t\t\t\t\t\t\tvalence_with_loss.append((vl,temp_LOSS))\n",
    "\n",
    "\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\tvalence_with_loss.append((valence_list,ori_LOSS))\n",
    "\t\t\t\tprint(time.time()-timestamp)\n",
    "\t\t\t\ttimestamp = time.time()\n",
    "\n",
    "\t\treturn valence_with_loss\n",
    "\n",
    "\n",
    "\tdef tune_by_resonance(self, LOSS, res, global_nomalized_dict, global_sigma_dict, global_mean_dict):\n",
    "\t\tvalence_with_loss = self.apply_resonance(res.super_atom_idx_list, \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t res.sum_of_valence, \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t LOSS, \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t res,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t global_nomalized_dict, \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t global_sigma_dict, \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t global_mean_dict)  #first run\n",
    "\t\t#print(valence_with_loss)\n",
    "\t\tcheck = {}\n",
    "\t\t#print(valence_with_loss)\n",
    "\t\tfor vwl in valence_with_loss:\n",
    "\t\t\tif str(sorted(vwl[0])) not in check:\n",
    "\t\t\t\tcheck[str(sorted(vwl[0]))] = [vwl]\n",
    "\t\t\telse:\n",
    "\t\t\t\tif vwl not in check[str(sorted(vwl[0]))]:\n",
    "\t\t\t\t\tcheck[str(sorted(vwl[0]))].append(vwl)\n",
    "\n",
    "\t\tif res.resonance_order == \"2\":\n",
    "\t\t\t#valence_with_loss = random.sample(valence_with_loss, 100)\n",
    "\t\t\tprint(\"length:\",len(valence_with_loss))\n",
    "\t\t\tfor vwl in valence_with_loss:\n",
    "\t\t\t\tprime_valence_with_loss = self.apply_resonance(res.super_atom_idx_list, \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t   vwl[0], \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t   vwl[1], \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t   res, \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t   global_nomalized_dict, \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t   global_sigma_dict, \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t   global_mean_dict)\n",
    "\t\t\t\tfor p in prime_valence_with_loss:\n",
    "\t\t\t\t\tif str(sorted(p[0])) not in check:\n",
    "\t\t\t\t\t\tcheck[str(sorted(p[0]))] = [p]\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\tif p not in check[str(sorted(p[0]))]:\n",
    "\t\t\t\t\t\t\tcheck[str(sorted(p[0]))].append(p)\n",
    "\n",
    "\t\tpossible_resonance = {}\n",
    "\t\tfor k,v in check.items():\n",
    "\t\t\tavg_loss = sum(l[1] for l in v)/len(v)\n",
    "\t\t\tpossible_resonance[avg_loss] = v\n",
    "\n",
    "\t\tkey = sorted(possible_resonance.keys())[0]\n",
    "\n",
    "\t\tthe_resonance_result = possible_resonance[key]\n",
    "\t\tavg_LOSS = sum([i[1] for i in the_resonance_result])/len(the_resonance_result)\n",
    "\t\t#one_sum_of_valence = the_resonance_result[0][0]\n",
    "\t\tresonance_valence_list = [i[0] for i in the_resonance_result]\n",
    "\t\treturn avg_LOSS, the_resonance_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3964df6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Oxidation_States(m_id,i, atom_pool):\n",
    "\n",
    "    GFOS = GET_FOS()\n",
    "    delta_X = 0.1\n",
    "    tolerance_list = valid_t_dict[m_id]\n",
    "    print(tolerance_list)\n",
    "    corr_t = []\n",
    "    ls = time.time()\n",
    "        \n",
    "    for t in tolerance_list:\n",
    "        print(t)\n",
    "        res = RESULT()\n",
    "        res.mid = m_id\n",
    "        TN = TUNE()\n",
    "        #try:\n",
    "        if True:\n",
    "            GFOS.loss_loop(m_id, delta_X, t, tolerance_list, res)\n",
    "            print(res.idx)\n",
    "            temp_pair_info = spider_pair_length_with_CN_unnorm(res.sum_of_valence, res)\n",
    "\n",
    "            #now, the matched dict is the global normalization normed dict. \n",
    "            loss = cal_loss_func_by_MAP(temp_pair_info, \n",
    "                                        global_normalized_normed_dict, \n",
    "                                        global_sigma_dict, \n",
    "                                        global_mean_dict)\n",
    "            N_spec = len(res.species_uni_list)\n",
    "            res.initial_vl = res.sum_of_valence\n",
    "            \n",
    "            if len(res.super_atom_idx_list) > 0:\n",
    "                if res.resonance_flag:\n",
    "                    avg_LOSS, the_resonance_result = TN.tune_by_resonance(loss,\n",
    "                                                                          res, \n",
    "                                                                          global_normalized_normed_dict,\n",
    "                                                                          global_sigma_dict, \n",
    "                                                                          global_mean_dict)\n",
    "                    res.final_vl = the_resonance_result[0][0]\n",
    "                    same_after_resonance = True if res.final_vl == res.initial_vl else False\n",
    "                    res.sum_of_valence = res.final_vl\n",
    "                    print(\"Here\")\n",
    "\n",
    "                if atom_pool == \"super\":\n",
    "                    process_atom_idx_list = res.super_atom_idx_list\n",
    "                if atom_pool == \"link\":\n",
    "                    process_atom_idx_list = res.link_atom_idx_list\n",
    "                if atom_pool == \"all\":\n",
    "                    process_atom_idx_list = res.idx \n",
    "\n",
    "                LOSS, res.final_vl = TN.tune_by_redox_in_certain_range_by_MAP(process_atom_idx_list, \n",
    "                                                                              loss, \n",
    "                                                                              res.sum_of_valence,\n",
    "                                                                              0,\n",
    "                                                                              res,\n",
    "                                                                              global_normalized_normed_dict,\n",
    "                                                                              global_sigma_dict, \n",
    "                                                                              global_mean_dict)\n",
    "                res.sum_of_valence = res.final_vl\n",
    "                same_after_tunation = True if res.final_vl == res.initial_vl else False\n",
    "                same_after_resonance = True\n",
    "                \n",
    "            else:\n",
    "                res.final_vl = res.initial_vl\n",
    "                same_after_tunation = True\n",
    "                same_after_resonance = True\n",
    "                LOSS = loss\n",
    "                \n",
    "            parameters = {m_id: [res.resonance_flag, same_after_tunation, same_after_resonance]}\n",
    "            \n",
    "            loss_value = 1**N_spec * LOSS\n",
    "            corr_t.append((t,loss_value,res))\n",
    "        #except:\n",
    "        else:\n",
    "            None\n",
    "\n",
    "    #try:\n",
    "    if True:\n",
    "        chosen_one = sorted(corr_t, key = lambda x:x[1])[0]\n",
    "        res = chosen_one[2]\n",
    "        t = chosen_one[0]\n",
    "        #parameters = [m_id, LOSS, res.final_vl]\n",
    "        #for loop\n",
    "        temp_pair_info_normed = spider_pair_length_with_CN_normed(res)\n",
    "        temp_pair_info = spider_bond_length(res)\n",
    "\n",
    "        single_result_dict_normed = {t:temp_pair_info_normed}\n",
    "        single_result_dict = {t:temp_pair_info}\n",
    "\n",
    "        OS_result_with_ele = sorted([(i,j) for i,j in zip(res.final_vl, res.elements_list)], key = lambda x :x[1])\n",
    "        OS_result = [ij[0] for ij in OS_result_with_ele]\n",
    "\n",
    "        normalized_single_result_info = normalization(single_result_dict_normed)\n",
    "        parameters = [m_id, normalized_single_result_info, single_result_dict, OS_result]\n",
    "        tc = time.time() - ls\n",
    "        print(\"Got the Formal Oxidation State of the %sth structure %s in %s seconds.\"%(i,m_id,tc))\n",
    "        print(time.strftime('%Y-%m-%d %H:%M:%S', time.localtime()))\n",
    "        return parameters\n",
    "    #except:\n",
    "    else:\n",
    "        parameters = [m_id, None, None, None]\n",
    "        tc = time.time() - ls\n",
    "        print(\"Failed to analyze the %sth structure %s in %s seconds.\"%(i,m_id,tc))\n",
    "        print(time.strftime('%Y-%m-%d %H:%M:%S', time.localtime()))\n",
    "        return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "88be61c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "36*5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7efab0f3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.1, 1.11, 1.12, 1.13, 1.14, 1.15, 1.16, 1.18, 1.19, 1.21, 1.23, 1.24]\n",
      "1.1\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]\n",
      "Here\n",
      "1.11\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]\n",
      "Here\n",
      "1.12\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]\n",
      "Here\n",
      "1.13\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]\n",
      "Here\n",
      "1.14\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]\n",
      "Here\n",
      "1.15\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]\n",
      "Here\n",
      "1.16\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]\n",
      "Here\n",
      "1.18\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]\n",
      "1.19\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]\n",
      "Here\n",
      "1.21\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]\n",
      "Here\n",
      "1.23\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]\n",
      "Here\n",
      "1.24\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]\n",
      "Got the Formal Oxidation State of the 0th structure mp-1228217.cif in 1631.3266243934631 seconds.\n",
      "2023-11-14 12:48:10\n",
      "1631.3326148986816\n"
     ]
    }
   ],
   "source": [
    "s = time.time()\n",
    "m_id = \"mp-1228217.cif\"\n",
    "i = 0\n",
    "atom_pool = \"all\"\n",
    "parameter = get_Oxidation_States(m_id,i, atom_pool)\n",
    "e = time.time()\n",
    "print(e-s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34088c5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GFOS",
   "language": "python",
   "name": "gfos"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
